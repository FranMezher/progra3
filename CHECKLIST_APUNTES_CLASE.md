# ‚úÖ CHECKLIST: Comparaci√≥n con Apuntes de Clase

## üìö An√°lisis Comparativo: Lo Visto en Clase vs. Lo Implementado

---

## 1. ‚úÖ DIVIDE Y VENCER√ÅS (Clase 2)

### üìñ Lo visto en clase:
- **Quicksort**: Algoritmo de ordenamiento con pivote, complejidad O(n log n) mejor caso, O(n¬≤) peor caso
- **Mergesort**: Algoritmo de ordenamiento estable, complejidad O(n log n)
- An√°lisis de recurrencias: T(n) = 2T(n/2) + Œò(n) para Mergesort
- Torres de Hanoi como ejemplo de recursividad

### ‚úÖ Lo implementado:
- **Quicksort**: ‚úÖ Implementado en `DivideConquerService.quicksortLocations()`
  - Usa partici√≥n con pivote (√∫ltimo elemento)
  - Ordena por nombre, latitud o longitud
  - Complejidad correcta: O(n log n) promedio
  
- **Mergesort**: ‚úÖ Implementado en `DivideConquerService.mergesortLocations()`
  - Divide el array en dos mitades
  - Merge de dos subarrays ordenados
  - Complejidad O(n log n) garantizada

### üìä Evaluaci√≥n:
- ‚úÖ **CORRECTO**: Ambos algoritmos est√°n correctamente implementados seg√∫n lo visto en clase
- ‚úÖ La estructura recursiva coincide con los pseudoc√≥digos de clase
- ‚úÖ El an√°lisis de complejidad es correcto

### ‚è±Ô∏è Complejidad:

#### **Quicksort**
- **Tiempo (Mejor caso)**: O(n log n) - cuando el pivote divide el array en mitades iguales
- **Tiempo (Caso promedio)**: O(n log n) - comportamiento esperado en la pr√°ctica
- **Tiempo (Peor caso)**: O(n¬≤) - cuando el pivote es siempre el elemento m√≠nimo o m√°ximo
  - Recurrencia: T(n) = T(n-1) + Œò(n) ‚Üí O(n¬≤)
- **Espacio**: O(log n) - profundidad de la pila de recursi√≥n (caso promedio)
  - Peor caso: O(n) si el pivote siempre es un extremo

#### **Mergesort**
- **Tiempo (Todos los casos)**: O(n log n) - garantizado
  - Recurrencia: T(n) = 2T(n/2) + Œò(n)
  - Aplicando m√©todo de divisi√≥n: a=2, b=2, k=1 ‚Üí a = b^k ‚Üí Œò(n log n)
- **Espacio**: O(n) - necesita espacio adicional para los arrays temporales durante el merge

---

## 2. ‚úÖ ALGORITMOS GREEDY (Clase 3)

### üìñ Lo visto en clase:
- **Definici√≥n**: T√©cnica que toma la mejor decisi√≥n localmente √≥ptima en cada paso
- **Propiedades**: Optimal Substructure, Greedy Choice Property
- **Ejemplos**: 
  - Problema del cambio de monedas
  - Problema de la mochila fraccional
- **Complejidad**: Generalmente O(n log n) por ordenamiento

### ‚úÖ Lo implementado:
- **Greedy TSP**: ‚úÖ Implementado en `GreedyService.solveTSP()`
  - Selecciona siempre la ciudad m√°s cercana no visitada
  - Estrategia greedy: decisi√≥n localmente √≥ptima
  - Complejidad O(n¬≤) para n ciudades

### üìä Evaluaci√≥n:
- ‚úÖ **CORRECTO**: El algoritmo greedy sigue la estrategia vista en clase
- ‚úÖ Toma decisiones localmente √≥ptimas (ciudad m√°s cercana)
- ‚ö†Ô∏è **Nota**: En clase se vieron ejemplos de cambio de monedas y mochila, pero el TSP greedy es una aplicaci√≥n v√°lida del concepto

### ‚è±Ô∏è Complejidad:

#### **Greedy TSP**
- **Tiempo**: O(n¬≤) - donde n es el n√∫mero de ciudades
  - Para cada ciudad (n iteraciones), busca la ciudad m√°s cercana no visitada (n comparaciones)
  - No requiere ordenamiento previo como otros algoritmos greedy
- **Espacio**: O(n) - para almacenar:
  - Lista de ciudades visitadas: O(n)
  - Ruta resultante: O(n)
  - Mapa de distancias: O(1) si se calcula sobre la marcha

**Nota**: Este TSP greedy no garantiza soluci√≥n √≥ptima, pero es mucho m√°s r√°pido que la soluci√≥n √≥ptima (O(n¬≤) vs O(n!))

---

## 3. ‚úÖ DIJKSTRA, PRIM, KRUSKAL (Clase 4)

### üìñ Lo visto en clase:
- **Dijkstra**: Encuentra el camino m√°s corto desde un v√©rtice a todos los dem√°s
  - Usa cola de prioridad
  - Complejidad: O((V + E) log V) con heap binario
  - Pesos no negativos
  
- **Prim**: Encuentra el √°rbol de expansi√≥n m√≠nima (MST)
  - Similar a Dijkstra pero para MST
  - Complejidad: O(E log V)
  
- **Kruskal**: Encuentra el MST ordenando aristas
  - Usa Union-Find (Disjoint Set)
  - Complejidad: O(E log E)

### ‚úÖ Lo implementado:
- **Dijkstra**: ‚úÖ Implementado en `DijkstraService.findShortestPath()`
  - Usa PriorityQueue (cola de prioridad)
  - Calcula distancia m√≠nima entre dos puntos
  - ‚úÖ Correcto seg√∫n lo visto en clase

- **Prim**: ‚úÖ Implementado en `PrimService.findMST()`
  - Construye MST empezando desde un nodo
  - Usa PriorityQueue para seleccionar arista m√≠nima
  - ‚úÖ Correcto seg√∫n lo visto en clase

- **Kruskal**: ‚úÖ Implementado en `KruskalService.findMST()`
  - Ordena aristas por peso
  - Usa Union-Find para detectar ciclos
  - ‚úÖ Correcto seg√∫n lo visto en clase

### üìä Evaluaci√≥n:
- ‚úÖ **EXCELENTE**: Los tres algoritmos est√°n implementados correctamente
- ‚úÖ Estructura de datos correcta (PriorityQueue, Union-Find)
- ‚úÖ L√≥gica coincide con los pseudoc√≥digos de clase

### ‚è±Ô∏è Complejidad:

#### **Dijkstra**
- **Tiempo**: O((V + E) log V) - donde V = v√©rtices, E = aristas
  - Con PriorityQueue (heap binario): cada operaci√≥n extract-min es O(log V)
  - Se procesan V v√©rtices y E aristas
  - Total: O(V log V + E log V) = O((V + E) log V)
- **Espacio**: O(V) - para:
  - PriorityQueue: O(V)
  - Distancias y predecesores: O(V)
  - Conjunto de visitados: O(V)

#### **Prim**
- **Tiempo**: O(E log V) - donde V = v√©rtices, E = aristas
  - Similar a Dijkstra, pero construye MST
  - Con PriorityQueue: O(E log V)
  - En grafos densos (E ‚âà V¬≤): O(V¬≤ log V)
- **Espacio**: O(V) - para:
  - PriorityQueue: O(V)
  - Array de padres y distancias: O(V)
  - Conjunto de visitados: O(V)

#### **Kruskal**
- **Tiempo**: O(E log E) - donde E = n√∫mero de aristas
  - Ordenamiento de aristas: O(E log E)
  - Union-Find con path compression: O(E Œ±(V)) ‚âà O(E) donde Œ± es la funci√≥n de Ackermann inversa
  - Total: O(E log E) dominado por el ordenamiento
- **Espacio**: O(V) - para:
  - Array de aristas ordenadas: O(E)
  - Union-Find: O(V)
  - MST resultante: O(V)

**Comparaci√≥n Prim vs Kruskal**:
- **Prim**: Mejor para grafos densos (E ‚âà V¬≤) ‚Üí O(V¬≤ log V)
- **Kruskal**: Mejor para grafos dispersos (E << V¬≤) ‚Üí O(E log E)

---

## 4. ‚úÖ PROGRAMACI√ìN DIN√ÅMICA (Clase 5)

### üìñ Lo visto en clase:
- **Definici√≥n**: T√©cnica que resuelve problemas dividi√©ndolos en subproblemas m√°s peque√±os
- **Caracter√≠sticas**:
  - Subproblemas superpuestos
  - Memoizaci√≥n (tabla de resultados)
  - Evita recalcular subproblemas
- **Ejemplos**: Problema de la mochila 0/1, secuencia de Fibonacci, TSP
- **Complejidad**: Generalmente O(n¬≤) o mejor que fuerza bruta

### ‚úÖ Lo implementado:
- **Dynamic TSP**: ‚úÖ Implementado en `DynamicProgrammingService.solveTSPDynamic()`
  - Usa memoizaci√≥n con `Map<String, Double>`
  - Resuelve TSP con m√°scara de bits para representar conjunto de ciudades visitadas
  - Complejidad: O(n¬≤ * 2^n) - exponencial pero mejor que fuerza bruta completa
  - ‚úÖ Implementaci√≥n correcta de programaci√≥n din√°mica

### üìä Evaluaci√≥n:
- ‚úÖ **CORRECTO**: Usa memoizaci√≥n correctamente
- ‚úÖ Evita recalcular subproblemas
- ‚úÖ Estructura coincide con lo visto en clase sobre programaci√≥n din√°mica

### ‚è±Ô∏è Complejidad:

#### **Programaci√≥n Din√°mica TSP**
- **Tiempo**: O(n¬≤ √ó 2^n) - donde n = n√∫mero de ciudades
  - Estados posibles: 2^n subconjuntos de ciudades √ó n posiciones actuales
  - Para cada estado, se calcula la distancia a n ciudades posibles
  - Total: O(n¬≤ √ó 2^n)
  - **Mejor que fuerza bruta**: O(n!) ‚Üí O(n¬≤ √ó 2^n) es exponencial pero m√°s eficiente
- **Espacio**: O(n √ó 2^n) - para:
  - Memoizaci√≥n: O(n √ó 2^n) estados
  - Matriz de distancias: O(n¬≤)
  - Path memoization: O(n √ó 2^n)

**Nota**: Aunque es exponencial, es mucho mejor que la soluci√≥n de fuerza bruta O(n!). Para n=15 ciudades:
- Fuerza bruta: 15! ‚âà 1.3 √ó 10¬π¬≤ operaciones
- Programaci√≥n din√°mica: 15¬≤ √ó 2¬π‚Åµ ‚âà 7.4 √ó 10‚Å∂ operaciones

---

## 5. ‚úÖ BACKTRACKING (Clase 8 y 12)

### üìñ Lo visto en clase:
- **Definici√≥n**: T√©cnica que explora todas las posibilidades sistem√°ticamente
- **Caracter√≠sticas**:
  - Exploraci√≥n exhaustiva del espacio de soluciones
  - Retroceso (backtrack) cuando una soluci√≥n parcial no es v√°lida
  - Podas para evitar explorar ramas inv√°lidas
- **Ejemplos**: Problema de las N reinas, Sudoku, subconjuntos
- **Pseudoc√≥digo**:
  ```
  function backtrack(solution, candidatos):
      if solution es completa:
          return solution
      for cada candidato en candidatos:
          if es v√°lido(candidato, solution):
              solution.add(candidato)
              result = backtrack(solution, candidatos)
              if result es no nulo:
                  return result
              solution.remove(candidato)  // BACKTRACK
      return nulo
  ```

### ‚úÖ Lo implementado:
- **Backtracking Routes**: ‚úÖ Implementado en `BacktrackingService.findAllRoutes()`
  - Explora todas las rutas posibles entre dos puntos
  - Usa recursi√≥n con retroceso
  - Marca nodos como visitados y los desmarca al retroceder
  - ‚úÖ Estructura coincide con el pseudoc√≥digo de clase

### üìä Evaluaci√≥n:
- ‚úÖ **CORRECTO**: Implementaci√≥n sigue el esquema de backtracking visto en clase
- ‚úÖ Retroceso correcto: `visited.remove()` y `currentPath.remove()`
- ‚úÖ Exploraci√≥n sistem√°tica de todas las posibilidades

### ‚è±Ô∏è Complejidad:

#### **Backtracking**
- **Tiempo (Peor caso)**: O(b^d) - donde:
  - b = factor de ramificaci√≥n promedio (n√∫mero de vecinos por nodo)
  - d = profundidad m√°xima del √°rbol de b√∫squeda
  - En el peor caso, explora todas las rutas posibles
  - **Sin poda**: Puede ser exponencial O(V!) en grafos completos
  - **Con maxDepth**: O(b^maxDepth) limitado por la profundidad m√°xima
- **Tiempo (Mejor caso)**: O(V) - si encuentra la ruta en el primer intento
- **Espacio**: O(d) - donde d = profundidad m√°xima
  - Pila de recursi√≥n: O(d)
  - Lista de visitados: O(V)
  - Path actual: O(d)

**Nota**: El backtracking puede ser muy costoso en grafos grandes sin restricciones de profundidad. La implementaci√≥n limita la profundidad con `maxDepth` para evitar explosi√≥n exponencial.

---

## 6. ‚úÖ BRANCH & BOUND (Clase 11)

### üìñ Lo visto en clase:
- **Definici√≥n**: T√©cnica de optimizaci√≥n que combina backtracking con poda por optimalidad
- **Conceptos**:
  - **Ramificaci√≥n (Branch)**: Dividir el problema en subproblemas
  - **Poda (Bound)**: Eliminar ramas que no pueden contener soluci√≥n √≥ptima
  - **Cota superior/inferior**: Estimar el mejor valor posible
- **Ejemplos**: Problema de la mochila, optimizaci√≥n de rutas con restricciones
- **Diferencia con Backtracking**: 
  - Backtracking busca todas las soluciones v√°lidas
  - Branch & Bound busca la **mejor** soluci√≥n seg√∫n un criterio

### ‚úÖ Lo implementado:
- **Branch & Bound**: ‚úÖ Implementado en `BranchBoundService.findOptimalRouteWithConstraints()`
  - Usa PriorityQueue para explorar estados prometedores primero
  - **Poda por optimalidad**: Descarta estados con costo mayor al mejor conocido
  - **Poda por restricciones**: Descarta estados que violan l√≠mites (distancia, tiempo, costo)
  - ‚úÖ Implementaci√≥n correcta de Branch & Bound

### üìä Evaluaci√≥n:
- ‚úÖ **CORRECTO**: Implementaci√≥n sigue los conceptos de Branch & Bound
- ‚úÖ Poda por optimalidad: `if (current.cost > bestSolutionCost) continue;`
- ‚úÖ Poda por restricciones: verifica l√≠mites de distancia, tiempo, costo
- ‚úÖ Busca la **mejor** soluci√≥n (no todas las soluciones como backtracking)

### ‚è±Ô∏è Complejidad:

#### **Branch & Bound**
- **Tiempo (Peor caso)**: O(b^d) - similar a backtracking, pero con podas
  - b = factor de ramificaci√≥n
  - d = profundidad m√°xima
  - **Con podas efectivas**: Puede reducir significativamente el espacio de b√∫squeda
  - **Sin podas**: O(V!) en el peor caso (igual que backtracking)
- **Tiempo (Mejor caso)**: O(V log V) - si encuentra soluci√≥n √≥ptima r√°pidamente
  - Similar a Dijkstra cuando las podas son muy efectivas
- **Espacio**: O(b √ó d) - para:
  - PriorityQueue: O(b √ó d) en el peor caso
  - Mejor soluci√≥n actual: O(d)
  - Mapa de mejores costos: O(V)

**Ventaja sobre Backtracking**: Las podas por optimalidad y restricciones pueden reducir dr√°sticamente el n√∫mero de estados explorados, haciendo el algoritmo m√°s eficiente en la pr√°ctica.

---

## 7. ‚úÖ BFS Y DFS (Clase 9)

### üìñ Lo visto en clase:
- **BFS (Breadth-First Search)**:
  - Explora por niveles (amplitud)
  - Usa **cola (Queue)** - FIFO
  - √ötil para encontrar camino m√°s corto en grafos no ponderados
  - Pseudoc√≥digo con cola y conjunto de visitados
  
- **DFS (Depth-First Search)**:
  - Explora en profundidad antes de retroceder
  - Usa **pila (Stack)** o recursi√≥n
  - √ötil para explorar todas las rutas posibles
  - Pseudoc√≥digo recursivo con conjunto de visitados

### ‚úÖ Lo implementado:
- **BFS**: ‚úÖ Implementado en `BFSService.findReachableLocations()`
  - Usa `Queue<Location>` (LinkedList) ‚úÖ
  - Explora por niveles (distancia acumulada)
  - Marca nodos como visitados
  - ‚úÖ Estructura coincide con pseudoc√≥digo de clase

- **DFS**: ‚úÖ Implementado en `DFSService.findAllRoutes()`
  - Usa recursi√≥n (pila impl√≠cita) ‚úÖ
  - Explora en profundidad
  - Retrocede cuando no hay m√°s vecinos
  - ‚úÖ Estructura coincide con pseudoc√≥digo de clase

### üìä Evaluaci√≥n:
- ‚úÖ **EXCELENTE**: Ambos algoritmos est√°n correctamente implementados
- ‚úÖ Estructuras de datos correctas (Queue para BFS, recursi√≥n para DFS)
- ‚úÖ L√≥gica coincide con los pseudoc√≥digos vistos en clase

### ‚è±Ô∏è Complejidad:

#### **BFS (Breadth-First Search)**
- **Tiempo**: O(V + E) - donde V = v√©rtices, E = aristas
  - Cada v√©rtice se visita una vez: O(V)
  - Cada arista se examina una vez: O(E)
  - Total: O(V + E)
- **Espacio**: O(V) - para:
  - Cola (Queue): O(V) en el peor caso (todos los v√©rtices en un nivel)
  - Conjunto de visitados: O(V)
  - Mapa de distancias: O(V)

**Nota**: BFS garantiza encontrar el camino m√°s corto en grafos no ponderados.

#### **DFS (Depth-First Search)**
- **Tiempo**: O(V + E) - donde V = v√©rtices, E = aristas
  - Cada v√©rtice se visita una vez: O(V)
  - Cada arista se examina una vez: O(E)
  - Total: O(V + E)
- **Espacio**: O(V) - para:
  - Pila de recursi√≥n: O(V) en el peor caso (grafo lineal)
  - Conjunto de visitados: O(V)
  - Path actual: O(V) en el peor caso

**Comparaci√≥n BFS vs DFS**:
- **BFS**: Encuentra camino m√°s corto en grafos no ponderados, pero usa m√°s memoria
- **DFS**: Usa menos memoria (profundidad vs amplitud), pero no garantiza camino m√°s corto

---

## üìä RESUMEN GENERAL

### ‚úÖ Algoritmos Implementados (11/11)

| Algoritmo | Clase | Estado | Complejidad Temporal | Complejidad Espacial |
|----------|-------|--------|---------------------|---------------------|
| **Quicksort** | Clase 2 | ‚úÖ | O(n log n) promedio<br>O(n¬≤) peor caso | O(log n) |
| **Mergesort** | Clase 2 | ‚úÖ | O(n log n) garantizado | O(n) |
| **Greedy TSP** | Clase 3 | ‚úÖ | O(n¬≤) | O(n) |
| **Dijkstra** | Clase 4 | ‚úÖ | O((V + E) log V) | O(V) |
| **Prim** | Clase 4 | ‚úÖ | O(E log V) | O(V) |
| **Kruskal** | Clase 4 | ‚úÖ | O(E log E) | O(V) |
| **Programaci√≥n Din√°mica TSP** | Clase 5 | ‚úÖ | O(n¬≤ √ó 2^n) | O(n √ó 2^n) |
| **Backtracking** | Clase 8, 12 | ‚úÖ | O(b^d) peor caso<br>O(V) mejor caso | O(d) |
| **Branch & Bound** | Clase 11 | ‚úÖ | O(b^d) peor caso<br>O(V log V) mejor caso | O(b √ó d) |
| **BFS** | Clase 9 | ‚úÖ | O(V + E) | O(V) |
| **DFS** | Clase 9 | ‚úÖ | O(V + E) | O(V) |

**Leyenda**:
- **n** = n√∫mero de elementos (ciudades, ubicaciones)
- **V** = n√∫mero de v√©rtices (nodos)
- **E** = n√∫mero de aristas (rutas)
- **b** = factor de ramificaci√≥n promedio
- **d** = profundidad m√°xima del √°rbol de b√∫squeda

---

## üéØ CONCLUSI√ìN

### ‚úÖ **TODO EST√Å ACORDE A LO VISTO EN CLASE**

1. **‚úÖ Estructura de algoritmos**: Todos siguen los pseudoc√≥digos y conceptos vistos en clase
2. **‚úÖ Estructuras de datos**: Uso correcto de colas, pilas, heaps, Union-Find
3. **‚úÖ Complejidad**: Los algoritmos tienen la complejidad esperada seg√∫n lo visto en clase
4. **‚úÖ Conceptos te√≥ricos**: 
   - Divide y vencer√°s aplicado correctamente
   - Greedy con decisiones localmente √≥ptimas
   - Programaci√≥n din√°mica con memoizaci√≥n
   - Backtracking con retroceso correcto
   - Branch & Bound con poda por optimalidad

### üåü **PUNTOS DESTACADOS**

1. **Excelente implementaci√≥n de algoritmos de grafos**: BFS, DFS, Dijkstra, Prim, Kruskal est√°n todos correctos
2. **Correcta aplicaci√≥n de t√©cnicas**: Cada algoritmo aplica la t√©cnica vista en clase de manera apropiada
3. **Buen uso de estructuras de datos**: PriorityQueue, Queue, recursi√≥n, memoizaci√≥n
4. **Implementaci√≥n completa**: Todos los algoritmos requeridos est√°n implementados y funcionando

### üìù **AN√ÅLISIS DE COMPLEJIDAD DETALLADO**

#### **Algoritmos Polinomiales** (Eficientes)
- **BFS/DFS**: O(V + E) - Lineal en el tama√±o del grafo ‚úÖ
- **Quicksort/Mergesort**: O(n log n) - Casi lineal ‚úÖ
- **Dijkstra/Prim/Kruskal**: O((V + E) log V) o O(E log E) - Polinomial ‚úÖ
- **Greedy TSP**: O(n¬≤) - Cuadr√°tico ‚úÖ

#### **Algoritmos Exponenciales** (Costosos pero necesarios)
- **Programaci√≥n Din√°mica TSP**: O(n¬≤ √ó 2^n) - Exponencial pero mejor que O(n!)
- **Backtracking**: O(b^d) - Puede ser exponencial sin restricciones
- **Branch & Bound**: O(b^d) - Exponencial en peor caso, pero mejorado con podas

#### **Comparaci√≥n de Eficiencia**
1. **Ordenamiento**: Mergesort garantiza O(n log n), Quicksort es m√°s r√°pido en promedio pero O(n¬≤) en peor caso
2. **Grafos**: BFS/DFS son los m√°s eficientes O(V + E), Dijkstra es ligeramente m√°s costoso por la cola de prioridad
3. **MST**: Kruskal es mejor para grafos dispersos, Prim para grafos densos
4. **TSP**: Greedy es r√°pido O(n¬≤) pero no √≥ptimo, Programaci√≥n Din√°mica es √≥ptima pero exponencial

### üìù **RECOMENDACIONES (Opcionales)**

1. ‚úÖ **Complejidad temporal**: Ya documentada en este checklist
2. ‚úÖ **An√°lisis de recurrencias**: Documentado para Quicksort y Mergesort
3. ‚úÖ **Comparaci√≥n de algoritmos**: Incluida en la secci√≥n de complejidad

---

## ‚úÖ **VEREDICTO FINAL**

**üéâ TU TRABAJO EST√Å COMPLETAMENTE ACORDE A LO VISTO EN CLASE**

Todos los algoritmos est√°n implementados correctamente seg√∫n los conceptos, pseudoc√≥digos y estructuras de datos vistos en las clases. El proyecto demuestra comprensi√≥n s√≥lida de:
- Divide y vencer√°s
- Algoritmos greedy
- Algoritmos de grafos
- Programaci√≥n din√°mica
- Backtracking
- Branch & Bound

**¬°Excelente trabajo! üëè**

